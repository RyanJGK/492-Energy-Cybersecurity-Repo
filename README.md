# ICS Security Monitoring System

**Real-time security monitoring for energy sector Industrial Control Systems (ICS) and authentication infrastructure**

[![Python](https://img.shields.io/badge/Python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-Proprietary-red.svg)]()
[![Compliance](https://img.shields.io/badge/Compliance-NERC_CIP%20%7C%20IEC_62443%20%7C%20NIST_SP_800--82-green.svg)]()

---

## ğŸ“˜ Overview

This project provides a **production-grade security monitoring platform** designed for critical energy infrastructure. It combines **IT security** (authentication fraud detection) with **OT security** (industrial protocol monitoring) in a unified, Kafka-based event streaming architecture.

### Key Capabilities

- **ğŸ” Authentication Security Agent** â€“ Detects credential abuse, token reuse, velocity attacks, geo anomalies, and disposable domains
- **âš™ï¸ OT Protocol Monitoring** â€“ Deep packet inspection for Modbus, DNP3, IEC 61850, IEC 104 protocols
- **ğŸš¨ Real-time Alerting** â€“ Multi-severity alerts with Slack, PagerDuty, and SIEM integrations
- **ğŸ“Š SIEM Integration** â€“ Pre-built dashboards and correlation rules for Elastic, Splunk, Sentinel, and Grafana
- **âœ… Compliance-Ready** â€“ Enforces NERC CIP, IEC 62443, NIST SP 800-82 requirements including PII retention, audit logging, and data governance

---

## ğŸ§© Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Data Sources                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Auth Events    â”‚  OT Network Taps   â”‚  Email Delivery Events   â”‚
â”‚  (Kafka Topic)  â”‚  (PCAP/SPAN)       â”‚  (Database/Kafka)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                     â”‚
         â–¼                   â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Email Verif.    â”‚  â”‚ OT Tracking      â”‚  â”‚ Email Recording  â”‚
â”‚ Agent           â”‚  â”‚ Agent            â”‚  â”‚ Agent            â”‚
â”‚                 â”‚  â”‚                  â”‚  â”‚                  â”‚
â”‚ â€¢ Token Reuse   â”‚  â”‚ â€¢ New Masters    â”‚  â”‚ â€¢ Bounce Detect  â”‚
â”‚ â€¢ Velocity      â”‚  â”‚ â€¢ Unknown Func   â”‚  â”‚ â€¢ Privacy Scan   â”‚
â”‚ â€¢ Geo Anomaly   â”‚  â”‚ â€¢ Zonal Flow     â”‚  â”‚                  â”‚
â”‚ â€¢ Disposables   â”‚  â”‚ â€¢ Safety Range   â”‚  â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  Alerts Topic   â”‚
                     â”‚  (Kafka)        â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼               â–¼               â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Elastic  â”‚  â”‚   Splunk   â”‚  â”‚   Grafana    â”‚
       â”‚ Detection â”‚  â”‚ Correlationâ”‚  â”‚  Dashboards  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Installation

### Prerequisites

- **Python 3.13+**
- **Docker & docker-compose** (for lab environment)
- **Kafka cluster** (or use local Docker)
- **PostgreSQL 16+** (for state persistence)

### 1. Clone and Install Dependencies

```bash
git clone <repository-url>
cd ics-security-monitoring
pip install -r requirements.txt
```

### 2. Configure Environment

Copy the template configuration and fill in secrets:

```bash
cp config.yaml config.local.yaml
# Edit config.local.yaml with your environment-specific settings
# Use Vault or secret manager references instead of inline passwords
```

### 3. Set Up Infrastructure (Lab Mode)

For local testing with Docker:

```bash
docker compose -f docker-compose.lab.yml up -d --build
```

This starts:
- Kafka + Zookeeper
- PostgreSQL with schema initialization
- Schema Registry
- Email verification agent
- OT collector

### 4. Initialize Kafka Topics

```bash
docker exec -it $(docker ps -q -f name=kafka) kafka-topics \
  --bootstrap-server kafka:9092 \
  --create --topic auth-verification-events \
  --partitions 12 --replication-factor 1

docker exec -it $(docker ps -q -f name=kafka) kafka-topics \
  --bootstrap-server kafka:9092 \
  --create --topic ot-network-events \
  --partitions 24 --replication-factor 1
```

See `kafka_topics.yaml` for full topic configuration across environments.

---

## ğŸš€ Usage

### Running the Email Verification Agent

```python
from email_verification.agent import EmailVerificationAgent
from email_verification.rules.velocity import VelocityRule
from email_verification.rules.token_reuse import TokenReuseRule
from email_verification.context import KVStore

rules = [VelocityRule(), TokenReuseRule()]
cfg = {
    "policy": {
        "ip_rate_limits": {"window_seconds": 300, "max_auth_requests": 50}
    }
}

agent = EmailVerificationAgent(
    consumer=kafka_consumer,  # Your Kafka consumer
    rules=rules,
    cfg=cfg,
    kv=KVStore()
)

agent.run()  # Runs indefinitely until SIGTERM/SIGINT
```

### Running the OT Tracking Agent

```python
from ot_collector.ot_tracking_agent import OTTrackingAgent
from schemas import OTProtocolFrame

agent = OTTrackingAgent()
agent.load_baseline([
    ("10.10.0.2", "10.10.0.10", "modbus", ["3", "4", "6"])
])

# Ingest live frames
for frame in live_pcap_stream():
    alerts = agent.ingest_frame(frame)
    for alert in alerts:
        publish_to_kafka(alert)
```

### Demo Scripts

**Email Verification Demo** (processes CSV of auth events):
```bash
python scripts/demo.py email --csv data/auth_events.csv
```

**OT Protocol Demo** (synthetic Modbus frames):
```bash
python scripts/demo.py ot
```

**Replay Auth Events from CSV**:
```bash
python scripts/replay_auth_csv.py data/auth_events.csv
```

**Run OT Collector on PCAP**:
```bash
PCAP_PATH=pcaps/sample_modbus.pcap python scripts/run_ot_collector.py
```

---

## ğŸ§± Project Structure

```
/workspace
â”œâ”€â”€ config/
â”‚   â””â”€â”€ zones.yaml                  # OT network zone definitions
â”œâ”€â”€ config.yaml                     # Main system configuration template
â”œâ”€â”€ kafka_topics.yaml               # Kafka topic definitions per environment
â”œâ”€â”€ schemas.py                      # Event schemas (AuthVerificationRequested, OTProtocolFrame, etc.)
â”‚
â”œâ”€â”€ email_verification/             # Authentication fraud detection agent
â”‚   â”œâ”€â”€ agent.py                    # Main agent loop with Kafka consumer
â”‚   â”œâ”€â”€ rule_engine.py              # Rule executor framework
â”‚   â”œâ”€â”€ context.py                  # KVStore, Metrics, Alert abstractions
â”‚   â””â”€â”€ rules/
â”‚       â”œâ”€â”€ velocity.py             # Rate limiting & burst detection
â”‚       â”œâ”€â”€ token_reuse.py          # Replay attack detection
â”‚       â”œâ”€â”€ token_expiry.py         # Expired token usage
â”‚       â”œâ”€â”€ geo_anomaly.py          # Impossible travel detection
â”‚       â”œâ”€â”€ disposable_domain.py    # Temporary email domain blocking
â”‚       â””â”€â”€ dmarc_compliance.py     # Email authentication compliance
â”‚
â”œâ”€â”€ ot_collector/                   # OT protocol monitoring
â”‚   â”œâ”€â”€ ot_tracking_agent.py        # Main OT agent with zone enforcement
â”‚   â”œâ”€â”€ asset_manager.py            # Asset inventory and baseline learning
â”‚   â”œâ”€â”€ safety_controls.py          # Safety system interlocks
â”‚   â””â”€â”€ dissectors/
â”‚       â”œâ”€â”€ modbus.py               # Modbus/TCP parser
â”‚       â”œâ”€â”€ dnp3.py                 # DNP3 parser
â”‚       â”œâ”€â”€ iec104.py               # IEC 60870-5-104 parser
â”‚       â””â”€â”€ iec61850.py             # IEC 61850 MMS parser
â”‚
â”œâ”€â”€ email_recording/                # Email delivery event recorder
â”‚   â”œâ”€â”€ db.py                       # PostgreSQL persistence layer
â”‚   â””â”€â”€ schema_linter.py            # PII detection & redaction
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ demo.py                     # Standalone demo runner
â”‚   â”œâ”€â”€ replay_auth_csv.py          # Kafka producer from CSV
â”‚   â”œâ”€â”€ run_ot_collector.py         # PCAP file ingest
â”‚   â””â”€â”€ privacy_scan.py             # Log file PII scanner
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ asset_baseline.sql          # OT asset baseline queries
â”‚   â””â”€â”€ verification_audit.sql      # Auth event audit views
â”‚
â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ grafana_dashboard.json      # Pre-built Grafana dashboard
â”‚
â”œâ”€â”€ elastic/
â”‚   â””â”€â”€ detections.ndjson           # Elastic SIEM detection rules
â”‚
â”œâ”€â”€ splunk/
â”‚   â””â”€â”€ correlation_savedsearches.conf  # Splunk correlation searches
â”‚
â”œâ”€â”€ sentinel/
â”‚   â””â”€â”€ analytics_rules.json        # Azure Sentinel analytics rules
â”‚
â”œâ”€â”€ playbooks/
â”‚   â””â”€â”€ high_severity_playbooks.yaml    # Incident response playbooks
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ lab_runbook.md              # Lab deployment guide
â”‚   â”œâ”€â”€ ot_collector_placement.md   # OT collector installation guide
â”‚   â””â”€â”€ service_accounts_and_secrets.md  # Secrets management guide
â”‚
â”œâ”€â”€ docker-compose.lab.yml          # Lab environment orchestration
â””â”€â”€ requirements.txt                # Python dependencies
```

---

## ğŸ”§ Configuration

### Main Configuration (`config.yaml`)

Key sections:

- **`database`** â€“ PostgreSQL connection strings with Vault secret references
- **`kafka`** â€“ Brokers per environment (lab, staging, limited-prod, full-prod)
- **`alerts`** â€“ Slack, PagerDuty routing by severity
- **`policy`** â€“ Rate limits, token expiry, velocity windows
- **`compliance`** â€“ PII retention, hashing, audit logging (NERC CIP, IEC 62443, NIST SP 800-82)
- **`services`** â€“ Consumer groups, topic mappings

### Kafka Topics (`kafka_topics.yaml`)

Defines partitioning, retention, replication for:

- **`auth-verification-events`** â€“ 30-day retention, partitioned by `user_id`
- **`email-delivery-events`** â€“ 14-day retention, partitioned by domain
- **`ot-network-events`** â€“ 7-day retention (high volume), partitioned by protocol

### Zone Configuration (`config/zones.yaml`)

Define OT network zones and allowed flows:

```yaml
zones:
  - name: control
    cidrs: ["10.10.0.0/24"]
  - name: safety
    cidrs: ["10.20.0.0/24"]
  - name: corporate
    cidrs: ["192.168.0.0/16"]

allowed_flows:
  - src_zone: control
    dst_zone: safety
  - src_zone: control
    dst_zone: historians
```

---

## ğŸ§ª Development

### Running Tests

```bash
pytest tests/
```

### Privacy Scanning

Ensure no PII leaks in logs:

```bash
python scripts/privacy_scan.py logs/agent.log logs/ot_consumer.log
```

### Adding a New Detection Rule

**For Email Verification:**

1. Create `email_verification/rules/my_rule.py`
2. Extend the `Rule` base class
3. Implement `evaluate(event, context)` method
4. Add to agent initialization in `scripts/demo.py`

**For OT Tracking:**

1. Create a new rule in `ot_collector/ot_tracking_agent.py`
2. Extend the `Rule` base class
3. Implement `evaluate(frame, agent)` method
4. Add to `OTTrackingAgent.rules` list

### Tuning False Positive Rate

See `docs/lab_runbook.md` for FP tuning recommendations. Key levers:

- **VelocityRule**: Adjust `max_auth_requests` threshold
- **GeoAnomalyRule**: Change speed threshold (default 1000 km/h)
- **UnknownFunctionCodeRule**: Set to WARN for warmup period
- **OutOfRangeValueRule**: Customize per asset/tag learned ranges

---

## ğŸ§‘â€ğŸ’» Technologies Used

| Category | Technologies |
|----------|-------------|
| **Languages** | Python 3.13+ |
| **Event Streaming** | Apache Kafka (Confluent Platform 7.7.1), Schema Registry |
| **Database** | PostgreSQL 16 |
| **Packet Analysis** | dpkt (Python PCAP parsing) |
| **SIEM** | Elastic, Splunk, Azure Sentinel, Grafana |
| **Orchestration** | Docker, docker-compose |
| **Compliance** | NERC CIP, IEC 62443, NIST SP 800-82 |
| **Protocols** | Modbus/TCP, DNP3, IEC 60870-5-104, IEC 61850, OPC UA |

### Python Dependencies

- **`confluent-kafka>=2.5.0`** â€“ Kafka producer/consumer
- **`psycopg[binary]>=3.2.1`** â€“ PostgreSQL adapter
- **`PyYAML>=6.0.1`** â€“ Configuration parsing
- **`dpkt>=1.9.8`** â€“ PCAP packet dissection

---

## ğŸ“š Documentation

- **[Lab Runbook](docs/lab_runbook.md)** â€“ Step-by-step guide for lab deployment
- **[OT Collector Placement](docs/ot_collector_placement.md)** â€“ Network tap/SPAN configuration
- **[Service Accounts & Secrets](docs/service_accounts_and_secrets.md)** â€“ Vault integration guide

---

## ğŸš¨ Security & Compliance

### Data Governance

- **PII Handling**: Email addresses are hashed (SHA-256 with salt) before storage
- **Retention Policies**:
  - Auth events: 30 days
  - Email events: 14 days
  - OT events: 7 days (with export to cold storage)
- **Redaction**: Passwords, tokens, authorization headers excluded from logs
- **Audit**: All access to sensitive topics/tables logged to S3

### Compliance Standards

This system is designed to satisfy:

- **NERC CIP-005**: Electronic Security Perimeter monitoring
- **NERC CIP-007**: System Security Management (event logging)
- **IEC 62443-3-3**: System security requirements and security levels
- **NIST SP 800-82**: Guide to ICS Security

---

## ğŸ¤ Contributing

This is a proprietary system for energy sector critical infrastructure. Contributions are limited to authorized personnel.

### Development Workflow

1. Create a feature branch: `git checkout -b feature/my-rule`
2. Implement changes and add tests
3. Run linters and tests: `pytest tests/ && python scripts/privacy_scan.py`
4. Submit a pull request with detailed description
5. Ensure CI passes (linting, tests, privacy scan)

---

## ğŸ“ Support

For issues or questions:

- **SOC Team**: soc@energyco.example
- **OT Security Team**: otsec@energyco.example

---

## ğŸ“„ License

**Proprietary** â€“ Unauthorized use, distribution, or modification is prohibited.

---

## ğŸ”® Roadmap

- [ ] Add OPC UA dissector support
- [ ] Implement ML-based anomaly detection for OT baselines
- [ ] MITRE ATT&CK for ICS mapping for alerts
- [ ] Real-time risk scoring dashboard
- [ ] Integration with SOAR platforms (Cortex XSOAR, Splunk Phantom)
- [ ] Automated incident response playbooks

---

**Built with â¤ï¸ for critical infrastructure protection**
